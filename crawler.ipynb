{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/the/Library/Python/3.11/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/the/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: selenium in /Users/the/Library/Python/3.11/lib/python/site-packages (4.20.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/homebrew/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/the/Library/Python/3.11/lib/python/site-packages (from selenium) (0.25.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/the/Library/Python/3.11/lib/python/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/homebrew/lib/python3.11/site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in /opt/homebrew/lib/python3.11/site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/the/Library/Python/3.11/lib/python/site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/the/Library/Python/3.11/lib/python/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/homebrew/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Requirement already satisfied: outcome in /Users/the/Library/Python/3.11/lib/python/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/homebrew/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/the/Library/Python/3.11/lib/python/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /Users/the/Library/Python/3.11/lib/python/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/homebrew/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18106 entries, 0 to 18105\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   link    18106 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 141.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_link_data = pd.read_csv('data/links/link_data.csv')\n",
    "df_link_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18106\n"
     ]
    }
   ],
   "source": [
    "LIST_LINK_PRODUCT = df_link_data['link'].values.tolist()\n",
    "print(len(LIST_LINK_PRODUCT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Nhà riêng', '39511518'), ('Nhà riêng', '39250524'), ('Nhà biệt thự liền kề', '35464584'), ('Nhà mặt phố', '39813780'), ('Nhà biệt thự liền kề', '39815386'), ('Nhà mặt phố', '39857717'), ('Nhà riêng', '39718266'), ('Nhà biệt thự liền kề', '38137432'), ('Nhà biệt thự liền kề', '35991254'), ('Nhà riêng', '39813396'), ('Shophouse/Nhà phố thương mại', '39781734'), ('Nhà mặt phố', '39810164'), ('Nhà biệt thự liền kề', '38657225')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_type_estate_and_prId(url):\n",
    "    # Define regular expressions for matching prId\n",
    "    prId_pattern = r\"pr(\\d+)\"\n",
    "\n",
    "    # Match prId using regular expression\n",
    "    prId_match = re.search(prId_pattern, url)\n",
    "\n",
    "    # Extract prId if a match is found\n",
    "    prId = prId_match.group(1) if prId_match else None\n",
    "\n",
    "    # Extract type_estate based on specific strings in the URL\n",
    "    type_estate_keywords = {\n",
    "        'ban-nha-rieng': 'Nhà riêng',\n",
    "        'ban-nha-mat-pho': 'Nhà mặt phố',\n",
    "        'ban-nha-biet-thu-lien-ke': 'Nhà biệt thự liền kề',\n",
    "        'ban-shophouse-nha-pho-thuong-mai': 'Shophouse/Nhà phố thương mại'\n",
    "    }\n",
    "\n",
    "    type_estate = 'Unknown'\n",
    "    for keyword, type_name in type_estate_keywords.items():\n",
    "        if keyword in url:\n",
    "            type_estate = type_name\n",
    "            break\n",
    "\n",
    "    return type_estate, prId\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breadcrumb not found for URL: https://batdongsan.com.vn/ban-shophouse-nha-pho-thuong-mai-duong-nghiem-xuan-yem-phuong-dai-kim-prj-the-manor-central-park/-lien-ke-vua-o-vua-kinh-doanh-mat-oto-tranh-rong-30m2-pr39847124\n",
      "Breadcrumb not found for URL: https://batdongsan.com.vn/ban-nha-rieng-duong-thanh-binh-phuong-mo-lao/ban-la-khe-yen-nghia-phu-luong-ha-dong-hn-pr39844629\n",
      "Breadcrumb not found for URL: https://batdongsan.com.vn/ban-shophouse-nha-pho-thuong-mai-duong-nguyen-xien-phuong-dai-kim-prj-the-manor-central-park/chinh-chu-can-ban-mat-di-bo-gia-re-nhat-thi-truong-canh-truong-quoc-te-dwight-pr39748332\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[118], line 121\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scraped_properties\n\u001b[0;32m--> 121\u001b[0m LIST_PRODUCT \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_property_details\u001b[49m\u001b[43m(\u001b[49m\u001b[43mLIST_LINK_PRODUCT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/raw_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mprint\u001b[39m(LIST_PRODUCT)\n",
      "Cell \u001b[0;32mIn[118], line 104\u001b[0m, in \u001b[0;36mscrape_property_details\u001b[0;34m(urls, filename)\u001b[0m\n\u001b[1;32m    102\u001b[0m futures \u001b[38;5;241m=\u001b[39m {executor\u001b[38;5;241m.\u001b[39msubmit(extract_property_details, url): url \u001b[38;5;28;01mfor\u001b[39;00m url \u001b[38;5;129;01min\u001b[39;00m urls}\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/concurrent/futures/_base.py:243\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wait_timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    240\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    241\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 243\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m    246\u001b[0m     finished \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39mfinished_futures\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    627\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.7_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LIST_PRODUCT = []\n",
    "\n",
    "# Define a function to extract property details\n",
    "def extract_property_details(url):\n",
    "    property_details = {\n",
    "        'pr_id': '',\n",
    "        'type_estate': '',\n",
    "        'district': '',\n",
    "        'posted_date': '',\n",
    "        'area': '',\n",
    "        'price': '',\n",
    "        'legal_document': '',\n",
    "        'interior': '',\n",
    "        'num_bedrooms': '',\n",
    "        'num_bathrooms': '',\n",
    "        'num_floors': '',\n",
    "        'house_orientation': '',\n",
    "        'balcony_orientation': '',\n",
    "        'entrance': '',\n",
    "        'frontage': ''\n",
    "    }\n",
    "\n",
    "    property_details['type_estate'], property_details['pr_id'] = extract_type_estate_and_prId(url)\n",
    "\n",
    "    try:\n",
    "        # Set up Selenium WebDriver\n",
    "        with webdriver.Chrome() as driver:\n",
    "            driver.get(url)\n",
    "            \n",
    "            # Get the page source\n",
    "            page_source = driver.page_source\n",
    "\n",
    "        soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "        try:\n",
    "            # Find the breadcrumb element\n",
    "            breadcrumb = soup.find('div', class_='re__breadcrumb')\n",
    "            if breadcrumb:\n",
    "                level_3_link = breadcrumb.find('a', {'level': '3'})\n",
    "                if level_3_link:\n",
    "                    property_details['district'] = level_3_link.text\n",
    "            else:\n",
    "                print(f\"Breadcrumb not found for URL: {url}\")\n",
    "        except AttributeError as e:\n",
    "            print(f\"Error extracting district: {e}\")\n",
    "\n",
    "        # Extract posted date\n",
    "        try:\n",
    "            posted_date_span = soup.find('span', string='Ngày đăng')\n",
    "            if posted_date_span:\n",
    "                property_details['posted_date'] = posted_date_span.find_next_sibling('span').text.strip()\n",
    "        except AttributeError as e:\n",
    "            print(f\"Error extracting posted_date: {e}\")\n",
    "\n",
    "        # Extract property specifications\n",
    "        try:\n",
    "            specs_content = soup.find_all('div', class_='re__pr-specs-content-item')\n",
    "            # Mapping of titles to corresponding keys in property_details\n",
    "            title_map = {\n",
    "                'Diện tích': 'area',\n",
    "                'Mức giá': 'price',\n",
    "                'Pháp lý': 'legal_document',\n",
    "                'Nội thất': 'interior',\n",
    "                'Số phòng ngủ': 'num_bedrooms',\n",
    "                'Số toilet': 'num_bathrooms',\n",
    "                'Số tầng': 'num_floors',\n",
    "                'Hướng nhà': 'house_orientation',\n",
    "                'Hướng ban công': 'balcony_orientation',\n",
    "                'Đường vào': 'entrance',\n",
    "                'Mặt tiền': 'frontage'\n",
    "            }\n",
    "\n",
    "            # Extract and map property details\n",
    "            for item in specs_content:\n",
    "                title = item.find(class_='re__pr-specs-content-item-title').text.strip()\n",
    "                if title in title_map:\n",
    "                    property_details[title_map[title]] = item.find(class_='re__pr-specs-content-item-value').text.strip()\n",
    "        except AttributeError as e:\n",
    "            print(f\"Error extracting property details: {e}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to extract data from {url}: {e}\")\n",
    "\n",
    "    return property_details\n",
    "\n",
    "# Function to write property details to CSV\n",
    "def write_to_csv(data, filename):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False, mode='a', header=not pd.io.common.file_exists(filename))\n",
    "\n",
    "# Function to get existing pr_id from CSV\n",
    "def get_existing_pr_ids(filename):\n",
    "    if pd.io.common.file_exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        return set(df['pr_id'])\n",
    "    return set()\n",
    "\n",
    "def scrape_property_details(urls, filename):\n",
    "    existing_pr_ids = get_existing_pr_ids(filename)\n",
    "    scraped_properties = []\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = {executor.submit(extract_property_details, url): url for url in urls}\n",
    "        try:\n",
    "            for future in as_completed(futures):\n",
    "                url = futures[future]\n",
    "                try:\n",
    "                    result = future.result()\n",
    "                    if result['pr_id'] not in existing_pr_ids:\n",
    "                        scraped_properties.append(result)\n",
    "                        write_to_csv([result], filename)\n",
    "                        existing_pr_ids.add(result['pr_id'])\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to extract data from {url}: {e}\")\n",
    "        except KeyboardInterrupt:\n",
    "            for f in futures:\n",
    "                f.cancel()\n",
    "            raise\n",
    "\n",
    "    return scraped_properties\n",
    "\n",
    "LIST_PRODUCT = scrape_property_details(LIST_LINK_PRODUCT, 'data/raw_data.csv')\n",
    "print(LIST_PRODUCT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(LIST_PRODUCT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_link_product = pd.DataFrame(LIST_PRODUCT)\n",
    "df_link_product.to_csv('data/raw_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"data/raw_data.csv\")\n",
    "df1 = pd.read_csv(\"data/raw_data_2.csv\")\n",
    "df2 = pd.read_csv(\"data/raw_data_1.csv\")\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "mf = pd.concat([df, df1, df2], ignore_index=True)\n",
    "\n",
    "# Write the merged file to a new CSV\n",
    "mf.to_csv('data/raw_data_real.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Unnamed: 0           10000 non-null  int64 \n",
      " 1   type_estate          9091 non-null   object\n",
      " 2   district             9091 non-null   object\n",
      " 3   price_per_sqm        8093 non-null   object\n",
      " 4   posted_date          9082 non-null   object\n",
      " 5   area                 9082 non-null   object\n",
      " 6   price                9082 non-null   object\n",
      " 7   legal_document       7914 non-null   object\n",
      " 8   interior             5510 non-null   object\n",
      " 9   num_bedrooms         6358 non-null   object\n",
      " 10  num_bathrooms        5706 non-null   object\n",
      " 11  num_floors           8014 non-null   object\n",
      " 12  house_orientation    1947 non-null   object\n",
      " 13  balcony_orientation  1230 non-null   object\n",
      " 14  entrance             4401 non-null   object\n",
      " 15  frontage             6222 non-null   object\n",
      "dtypes: int64(1), object(15)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/raw_data_real.csv')\n",
    "df.info()\n",
    "# df.to_csv('data/raw_data_real.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/raw_data_real.csv')\n",
    "df.drop(['house_orientation', 'balcony_orientation'], axis=1, inplace=True)\n",
    "# # Drop rows with empty data\n",
    "# df.dropna(how='all', inplace=True)\n",
    "\n",
    "df.to_csv('data/raw_data_test.csv', index=False)\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn) (1.26.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m860.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.4.2-cp311-cp311-macosx_12_0_arm64.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.0-cp311-cp311-macosx_12_0_arm64.whl (30.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.3/30.3 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.4.2 scipy-1.13.0 threadpoolctl-3.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/raw_data_test.csv')\n",
    "# df[['num_floors']].to_csv('data/num_floors.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "      Unnamed: 0                    type_estate      district  \\\n",
      "0              0          Nhà biệt thự, liền kề       Hà Đông   \n",
      "1              1  Shophouse, nhà phố thương mại       Hà Đông   \n",
      "2              2                            NaN           NaN   \n",
      "3              3                    Nhà mặt phố     Hoàng Mai   \n",
      "4              4          Nhà biệt thự, liền kề     Long Biên   \n",
      "...          ...                            ...           ...   \n",
      "9995        9995                      Nhà riêng   Nam Từ Liêm   \n",
      "9996        9996                    Nhà mặt phố  Hai Bà Trưng   \n",
      "9997        9997                            NaN           NaN   \n",
      "9998        9998                    Nhà mặt phố  Hai Bà Trưng   \n",
      "9999        9999                    Nhà mặt phố     Hoàn Kiếm   \n",
      "\n",
      "         price_per_sqm posted_date      area       price  legal_document  \\\n",
      "0     ~173,12 triệu/m²  13/05/2024     80 m²    13,85 tỷ  Sổ đỏ/ Sổ hồng   \n",
      "1       ~36,8 triệu/m²  11/05/2024    625 m²       23 tỷ  Sổ đỏ/ Sổ hồng   \n",
      "2                  NaN         NaN       NaN         NaN             NaN   \n",
      "3     ~158,51 triệu/m²  13/05/2024  220,8 m²       35 tỷ  Sổ đỏ/ Sổ hồng   \n",
      "4                  NaN  12/05/2024    220 m²  Thỏa thuận             NaN   \n",
      "...                ...         ...       ...         ...             ...   \n",
      "9995  ~115,71 triệu/m²  09/05/2024     35 m²     4,05 tỷ  Sổ đỏ/ Sổ hồng   \n",
      "9996     ~720 triệu/m²  12/05/2024    200 m²      144 tỷ  Sổ đỏ/ Sổ hồng   \n",
      "9997               NaN         NaN       NaN         NaN             NaN   \n",
      "9998  ~712,96 triệu/m²  12/05/2024    108 m²       77 tỷ  Sổ đỏ/ Sổ hồng   \n",
      "9999  ~394,74 triệu/m²  06/05/2024    114 m²       45 tỷ  Sổ đỏ/ Sổ hồng   \n",
      "\n",
      "            interior num_bedrooms num_bathrooms num_floors entrance frontage  \n",
      "0             Đầy đủ      6 phòng       4 phòng     4 tầng      NaN      NaN  \n",
      "1             Đầy đủ     13 phòng      12 phòng        NaN     40 m     10 m  \n",
      "2                NaN          NaN           NaN        NaN      NaN      NaN  \n",
      "3     Không nội thất      3 phòng       2 phòng     3 tầng     10 m    6,3 m  \n",
      "4                NaN          NaN           NaN        NaN      NaN      NaN  \n",
      "...              ...          ...           ...        ...      ...      ...  \n",
      "9995          Đầy đủ      3 phòng       4 phòng     5 tầng    2,5 m    3,6 m  \n",
      "9996             NaN     10 phòng      12 phòng     9 tầng      NaN    7,2 m  \n",
      "9997             NaN          NaN           NaN        NaN      NaN      NaN  \n",
      "9998          Cơ bản          NaN           NaN     7 tầng      6 m      5 m  \n",
      "9999             NaN          NaN           NaN     3 tầng      NaN      NaN  \n",
      "\n",
      "[10000 rows x 14 columns]\n",
      "Cleaned and Encoded DataFrame:\n",
      "      Unnamed: 0  type_estate  district     price_per_sqm posted_date   area  \\\n",
      "0              0            3        11  ~173,12 triệu/m²  13/05/2024   80.0   \n",
      "1              1            6        11    ~36,8 triệu/m²  11/05/2024  625.0   \n",
      "3              3            4        10  ~158,51 triệu/m²  13/05/2024  220.8   \n",
      "4              4            3        12               NaN  12/05/2024  220.0   \n",
      "5              5            3        11     ~130 triệu/m²  13/05/2024  100.0   \n",
      "...          ...          ...       ...               ...         ...    ...   \n",
      "9993        9993            4         7     ~280 triệu/m²  09/05/2024   75.0   \n",
      "9995        9995            5        14  ~115,71 triệu/m²  09/05/2024   35.0   \n",
      "9996        9996            4         7     ~720 triệu/m²  12/05/2024  200.0   \n",
      "9998        9998            4         7  ~712,96 triệu/m²  12/05/2024  108.0   \n",
      "9999        9999            4         9  ~394,74 triệu/m²  06/05/2024  114.0   \n",
      "\n",
      "           price  legal_document  interior  num_bedrooms  num_bathrooms  \\\n",
      "0       13,85 tỷ             252       294             6              4   \n",
      "1          23 tỷ             252       294            13             12   \n",
      "3          35 tỷ             252       114             3              2   \n",
      "4     Thỏa thuận             139       146             6              6   \n",
      "5          13 tỷ             139       146             6              6   \n",
      "...          ...             ...       ...           ...            ...   \n",
      "9993       21 tỷ             252       146             6              6   \n",
      "9995     4,05 tỷ             252       294             3              4   \n",
      "9996      144 tỷ             252       146            10             12   \n",
      "9998       77 tỷ             252        42             6              6   \n",
      "9999       45 tỷ             252       146             6              6   \n",
      "\n",
      "      num_floors   entrance   frontage  \n",
      "0              4  12.181061   6.788656  \n",
      "1              4  40.000000  10.000000  \n",
      "3              3  10.000000   6.300000  \n",
      "4              4  12.181061   6.788656  \n",
      "5              4  12.181061   6.788656  \n",
      "...          ...        ...        ...  \n",
      "9993           5  12.181061   6.788656  \n",
      "9995           5   2.500000   3.600000  \n",
      "9996           9  12.181061   7.200000  \n",
      "9998           7   6.000000   5.000000  \n",
      "9999           3  12.181061   6.788656  \n",
      "\n",
      "[9091 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Display the original DataFrame\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Step 1: Remove rows with entirely empty critical fields\n",
    "critical_fields = ['type_estate', 'district', 'posted_date', 'area', 'price']\n",
    "df.dropna(subset=critical_fields, how='all', inplace=True)\n",
    "\n",
    "# Remove specific substrings and convert to appropriate types\n",
    "df['num_bedrooms'] = df['num_bedrooms'].str.replace(' phòng', '').astype(float)\n",
    "df['num_bathrooms'] = df['num_bathrooms'].str.replace(' phòng', '').astype(float)\n",
    "df['num_floors'] = df['num_floors'].str.replace(' tầng', '').astype(float)\n",
    "df['entrance'] = df['entrance'].str.replace(' m', '').str.replace(',', '.').astype(float)\n",
    "df['frontage'] = df['frontage'].str.replace(' m', '').str.replace(',', '.').astype(float)\n",
    "df['area'] = df['area'].str.replace(' m²', '').str.replace(',', '.').astype(float)\n",
    "\n",
    "# Step 3: Fill missing numerical values with the mean of their respective columns\n",
    "df['num_bedrooms'] = df['num_bedrooms'].fillna(df['num_bedrooms'].mean())\n",
    "df['num_bathrooms'] = df['num_bathrooms'].fillna(df['num_bathrooms'].mean())\n",
    "df['num_floors'] = df['num_floors'].fillna(df['num_floors'].mean())\n",
    "df['entrance'] = df['entrance'].fillna(df['entrance'].mean())\n",
    "df['frontage'] = df['frontage'].fillna(df['frontage'].mean())\n",
    "df['area'] = df['area'].fillna(df['area'].mean())\n",
    "\n",
    "# Step 4: Fill missing categorical values with 'Not provided'\n",
    "df.fillna({\n",
    "    'legal_document': 'Not provided',\n",
    "    'interior': 'Not provided'\n",
    "}, inplace=True)\n",
    "\n",
    "# Step 5: Standardize data types for cleaned numerical fields\n",
    "df['num_bedrooms'] = df['num_bedrooms'].astype(int)\n",
    "df['num_bathrooms'] = df['num_bathrooms'].astype(int)\n",
    "df['num_floors'] = df['num_floors'].astype(int)\n",
    "df['entrance'] = df['entrance'].astype(float)\n",
    "df['frontage'] = df['frontage'].astype(float)\n",
    "\n",
    "# Step 6: Normalize and encode categorical strings\n",
    "df['type_estate'] = df['type_estate'].str.strip()\n",
    "df['district'] = df['district'].str.strip()\n",
    "df['legal_document'] = df['legal_document'].str.strip()\n",
    "df['interior'] = df['interior'].str.strip()\n",
    "\n",
    "# Convert categorical fields to numerical codes if needed\n",
    "label_encoders = {}\n",
    "categorical_fields = ['type_estate', 'district', 'legal_document', 'interior']\n",
    "\n",
    "for field in categorical_fields:\n",
    "    le = LabelEncoder()\n",
    "    df[field] = le.fit_transform(df[field])\n",
    "    label_encoders[field] = le  # Store the label encoder if you need to inverse transform later\n",
    "\n",
    "# Display the cleaned and encoded DataFrame\n",
    "print(\"Cleaned and Encoded DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Optionally save the cleaned data to a new CSV file\n",
    "df.to_csv('cleaned_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
