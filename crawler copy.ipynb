{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/the/Library/Python/3.11/lib/python/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/the/Library/Python/3.11/lib/python/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# response = requests.get(\"https://bds.com.vn/mua-ban-nha-dat-ha-noi-page2000\")\n",
    "response = requests.get(\"https://alonhadat.com.vn/can-ban-nha-ha-noi-t1.htm\")\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "list_link = soup.findAll('div', 'ct_title')\n",
    "print(list_link)\n",
    "# link = list_link[1].find('a', 'vip')\n",
    "# print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####Done page12\n",
      "####Done page13\n",
      "####Done page14\n",
      "####Done page15\n",
      "####Done page16\n",
      "####Done page17\n",
      "####Done page18\n",
      "####Done page19\n",
      "####Done page20\n",
      "####Done page21\n",
      "####Done page22\n",
      "####Done page23\n",
      "####Done page24\n",
      "####Done page25\n",
      "####Done page26\n",
      "####Done page27\n",
      "####Done page28\n",
      "####Done page29\n",
      "####Done page30\n",
      "####Done page31\n",
      "####Done page32\n",
      "####Done page33\n",
      "####Done page34\n",
      "####Done page35\n",
      "####Done page36\n",
      "####Done page37\n",
      "####Done page38\n",
      "####Done page39\n",
      "####Done page40\n",
      "####Done page41\n",
      "####Done page42\n",
      "####Done page43\n",
      "####Done page44\n",
      "####Done page45\n",
      "####Done page46\n",
      "####Done page47\n",
      "####Done page48\n",
      "####Done page49\n",
      "####Done page50\n",
      "####Done page51\n",
      "####Done page52\n",
      "####Done page53\n",
      "####Done page54\n",
      "####Done page55\n",
      "####Done page56\n",
      "####Done page57\n",
      "####Done page58\n",
      "####Done page59\n",
      "####Done page60\n",
      "####Done page61\n",
      "####Done page62\n",
      "####Done page63\n",
      "####Done page64\n",
      "####Done page65\n",
      "####Done page66\n",
      "####Done page67\n",
      "####Done page68\n",
      "####Done page69\n",
      "####Done page70\n",
      "####Done page71\n",
      "####Done page72\n",
      "####Done page73\n",
      "####Done page74\n",
      "####Done page75\n",
      "####Done page76\n",
      "####Done page77\n",
      "####Done page78\n",
      "####Done page79\n",
      "####Done page80\n",
      "####Done page81\n",
      "####Done page82\n",
      "####Done page83\n",
      "####Done page84\n",
      "####Done page85\n",
      "####Done page86\n",
      "####Done page87\n",
      "####Done page88\n",
      "####Done page89\n",
      "####Done page90\n",
      "####Done page91\n",
      "####Done page92\n",
      "####Done page93\n",
      "####Done page94\n",
      "####Done page95\n",
      "####Done page96\n",
      "####Done page97\n",
      "####Done page98\n",
      "####Done page99\n",
      "####Done page100\n"
     ]
    }
   ],
   "source": [
    "LIST_LINK_PRODUCT = []\n",
    "\n",
    "for i in range(11,100):\n",
    "    try:\n",
    "        response = requests.get(\"https://alonhadat.com.vn/can-ban-nha-ha-noi-t1/trang-\" + str(i + 1) + \".htm\")\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        list_link = soup.findAll('div', 'ct_title')          \n",
    "        for item in list_link:\n",
    "            link = item.find('a', 'vip').get('href')\n",
    "            LIST_LINK_PRODUCT.append(\n",
    "                {\n",
    "                    'link': 'https://alonhadat.com.vn' + link\n",
    "                }\n",
    "            )\n",
    "        print('####Done page' + str(i + 1))\n",
    "    except Exception as e:\n",
    "        print('####Error get link ' + str(i + 1))\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(LIST_LINK_PRODUCT)\n",
    "# df = pd.DataFrame(LIST_LINK_PRODUCT)\n",
    "# existing_df = pd.read_csv('data/link_data.csv')\n",
    "# max_index = existing_df.index.max() + 1\n",
    "# df.to_csv('data/link_data.csv')\n",
    "df = pd.DataFrame(LIST_LINK_PRODUCT)\n",
    "existing_df = pd.read_csv('data/link_data.csv')\n",
    "last_index = existing_df.index.max()\n",
    "df.index = range(last_index + 1, last_index + 1 + len(df))\n",
    "df.to_csv('data/link_data.csv', mode='a', header=False, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"moreinfor\"><span class=\"price\"><span class=\"label\">Giá: </span> <span class=\"value\"> 12,2 tỷ </span></span><span class=\"square\"><span class=\"label\">Diện tích: </span> <span class=\"value\"> 67 m<sup>2</sup></span></span><div class=\"clear\"></div></div>\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(\"https://alonhadat.com.vn/toi-ban-toa-ccmn-1-nha-ra-pho-dai-la-du-do-dep-7-tang-thang-may-doanh-thu-60tr-th-13953435.html\")\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "more_info = soup.find('div', 'moreinfor')\n",
    "print(more_info)\n",
    "# price = more_info[0].findAll('span', 'price')[0].find('span', 'value').text\n",
    "# square = more_info[0].findAll('span', 'square')[0].find('span', 'value').text\n",
    "# print(\"price:\" + price)\n",
    "# print(\"square:\" + square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estate type: căn hộ chung cư\n",
      "Province: Hà Nội\n",
      "District: Quận Long Biên\n",
      "Ward: Phường Thạch Bàn\n",
      "Price: 2.50 tỷ\n",
      "Square: 72 m2\n",
      "Post date: 07/06/2023\n",
      "Number of bedroom: 2\n",
      "Number of toilet: 2\n",
      "Describe: \n",
      "                [Chính chủ] Cần bán căn hộ Chung cư tầng 10 CT2A rộng 72m2 ( 2 ngủ - 2 WC - 2 Logia) \n",
      "✅Full đồ nội thất: - Nội thất: Hệ Tủ bếp, 02 (Giường+ đệm) phòng ngủ, tủ áo, Sofa + bàn trà, Bàn + ghế làm việc, trần thạch cao, sàn gỗ .... \n",
      "✅ Thiết bị điện tử: TV, máy giặt, điều hòa, tủ lạnh, quạt, nóng lạnh... (tình trạng mới )\n",
      "✅ ⚡ Giá bán: 2.5 tỷ\n",
      "Địa chỉ: Chung cư CT2A - Tổ 9, Thạch Bàn, Long Biên, Hà Nội. SĐT: ☎️ 0946 204 777                                \n",
      "Tìm kiếm theo từ khóa:\n",
      "Mua bán nhà đất\n",
      "Mua bán nhà đất Hà Nội\n",
      "Mua bán nhà đất Quận Long Biên\n",
      "Mua bán nhà đất Phường Thạch Bàn\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "infoAddress = soup.find('ul', 'breadcrumb').findAll('li')\n",
    "estate_type = ' '.join(infoAddress[0].text.split()[2:])\n",
    "province = infoAddress[1].text\n",
    "district = infoAddress[2].text\n",
    "ward = infoAddress[3].text\n",
    "important_info = soup.findAll('ul', 'list-attr-hot')[0].findAll('li')\n",
    "price = important_info[0].findAll('span')[1].text\n",
    "square = important_info[1].findAll('span')[1].text\n",
    "post_date = important_info[2].findAll('span')[1].text\n",
    "describe = soup.find('div', 'ct-pr-sum').text\n",
    "numb_bedroom = ''\n",
    "numb_toilet = ''\n",
    "numb_floor = ''\n",
    "if len(soup.findAll('ul', 'list-attr-hot')) > 1:  \n",
    "  extent_info = soup.findAll('ul', 'list-attr-hot')[1].findAll('li')\n",
    "  for ele in extent_info:\n",
    "    if ele.findAll('span')[0].text == 'Số phòng ngủ :':\n",
    "      numb_bedroom = ele.findAll('span')[1].text\n",
    "    elif ele.findAll('span')[0].text == 'Số toilet :':\n",
    "      numb_toilet = ele.findAll('span')[1].text\n",
    "    elif ele.findAll('span')[0].text == 'Tầng :':\n",
    "      numb_floor = ele.findAll('span')[1].text\n",
    "print('Estate type:', estate_type)\n",
    "print('Province:', province)\n",
    "print('District:', district)\n",
    "print('Ward:', ward)\n",
    "print('Price:', price)\n",
    "print('Square:', square)\n",
    "print('Post date:', post_date)\n",
    "if numb_bedroom: \n",
    "  print('Number of bedroom:', numb_bedroom)\n",
    "if numb_toilet: \n",
    "  print('Number of toilet:', numb_toilet)\n",
    "if numb_floor: \n",
    "  print('Number of floor:', numb_floor)\n",
    "print('Describe:', describe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  4000 non-null   int64 \n",
      " 1   link        4000 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_link_data = pd.read_csv('data/link_data.csv')\n",
    "df_link_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "LIST_LINK_PRODUCT = df_link_data['link'].values.tolist()\n",
    "print(len(LIST_LINK_PRODUCT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_PRODUCT = []\n",
    "\n",
    "for i in range(len(LIST_LINK_PRODUCT)):\n",
    "    try:\n",
    "        response = requests.get(LIST_LINK_PRODUCT[i])\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        infoAddress = None\n",
    "        estate_type = None\n",
    "        province = None\n",
    "        district = None\n",
    "        ward = None\n",
    "        price = None\n",
    "        square = None\n",
    "        post_date = None\n",
    "        numb_bedroom = None\n",
    "        numb_toilet = None\n",
    "        numb_floor = None\n",
    "\n",
    "        try:\n",
    "            infoAddress = soup.find('ul', 'breadcrumb').findAll('li')\n",
    "        except: \n",
    "            print('error infoAddress')\n",
    "        try:\n",
    "            estate_type = ' '.join(infoAddress[0].text.split()[2:])\n",
    "        except: \n",
    "            print('error estate_type')\n",
    "        try:\n",
    "            province = infoAddress[1].text\n",
    "        except:\n",
    "            print('error province') \n",
    "        try:\n",
    "            district = infoAddress[2].text\n",
    "        except:\n",
    "            print('error district') \n",
    "        try:\n",
    "            ward = infoAddress[3].text\n",
    "        except:\n",
    "            print('error ward') \n",
    "        try:\n",
    "            important_info = soup.findAll('ul', 'list-attr-hot')[0].findAll('li')\n",
    "        except:\n",
    "            print('error important_info') \n",
    "        try:\n",
    "            price = important_info[0].findAll('span')[1].text\n",
    "        except:\n",
    "            print('error price') \n",
    "        try:\n",
    "            square = important_info[1].findAll('span')[1].text\n",
    "        except:\n",
    "            print('error square') \n",
    "        try:\n",
    "            post_date = important_info[2].findAll('span')[1].text\n",
    "        except:\n",
    "            print('error post_date') \n",
    "        try:\n",
    "            if len(soup.findAll('ul', 'list-attr-hot')) > 1:  \n",
    "                extent_info = soup.findAll('ul', 'list-attr-hot')[1].findAll('li')\n",
    "                for ele in extent_info:\n",
    "                    if ele.findAll('span')[0].text == 'Số phòng ngủ :':\n",
    "                        numb_bedroom = ele.findAll('span')[1].text\n",
    "                    elif ele.findAll('span')[0].text == 'Số toilet :':\n",
    "                        numb_toilet = ele.findAll('span')[1].text\n",
    "                    elif ele.findAll('span')[0].text == 'Tầng :':\n",
    "                        numb_floor = ele.findAll('span')[1].text\n",
    "        except:\n",
    "            print('error extent_info')\n",
    "        LIST_PRODUCT.append(\n",
    "            {\n",
    "                'estate_type': estate_type,\n",
    "                'province': province,\n",
    "                'district': district,\n",
    "                'ward': ward,\n",
    "                'price': price,\n",
    "                'square': square,\n",
    "                'post_date': post_date,\n",
    "                'numb_bedroom': numb_bedroom,\n",
    "                'numb_toilet': numb_toilet,\n",
    "                'numb_floor': numb_floor,\n",
    "            }\n",
    "        )\n",
    "        print('####Finish get sample ' + str(i + 1))\n",
    "    except Exception as e:\n",
    "        print('####Error get sample ' + str(i + 1))\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "print(len(LIST_PRODUCT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_link_product = pd.DataFrame(LIST_PRODUCT)\n",
    "df_link_product.to_csv('data/raw_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(\"data/raw_data.csv\")\n",
    "\n",
    "# Drop the 'link' and 'describe' columns\n",
    "df.drop(['link', 'describe'], axis=1, inplace=True)\n",
    "\n",
    "# Save the modified DataFrame back to a CSV file\n",
    "df.to_csv(\"data/raw_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4000 entries, 0 to 3999\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    4000 non-null   int64  \n",
      " 1   estate_type   3210 non-null   object \n",
      " 2   province      3210 non-null   object \n",
      " 3   district      3206 non-null   object \n",
      " 4   ward          3206 non-null   object \n",
      " 5   price         3824 non-null   object \n",
      " 6   square        3770 non-null   object \n",
      " 7   post_date     4000 non-null   object \n",
      " 8   numb_bedroom  3076 non-null   float64\n",
      " 9   numb_toilet   2864 non-null   float64\n",
      " 10  numb_floor    3155 non-null   float64\n",
      "dtypes: float64(3), int64(1), object(7)\n",
      "memory usage: 343.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/raw_data.csv')\n",
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
